{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6755881d",
   "metadata": {
    "papermill": {
     "duration": 0.007197,
     "end_time": "2024-11-04T17:41:22.623015",
     "exception": false,
     "start_time": "2024-11-04T17:41:22.615818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*Vlad 3.11.2024*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1619a01e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T17:41:22.637129Z",
     "iopub.status.busy": "2024-11-04T17:41:22.636797Z",
     "iopub.status.idle": "2024-11-04T17:41:31.425574Z",
     "shell.execute_reply": "2024-11-04T17:41:31.424553Z"
    },
    "papermill": {
     "duration": 8.798328,
     "end_time": "2024-11-04T17:41:31.427867",
     "exception": false,
     "start_time": "2024-11-04T17:41:22.629539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostClassifier, Pool, cv as catboostCV\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier, cv as lgbmCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "# SETTINGS\n",
    "pd.set_option(\"display.max_columns\", 600)\n",
    "test_path = \"/kaggle/input/train-one/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c23db",
   "metadata": {},
   "source": [
    "## All functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4e436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T17:41:31.443090Z",
     "iopub.status.busy": "2024-11-04T17:41:31.442205Z",
     "iopub.status.idle": "2024-11-04T17:41:31.450702Z",
     "shell.execute_reply": "2024-11-04T17:41:31.449898Z"
    },
    "papermill": {
     "duration": 0.017789,
     "end_time": "2024-11-04T17:41:31.452615",
     "exception": false,
     "start_time": "2024-11-04T17:41:31.434826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "\n",
    "def fast_auc(y_true, y_prob):\n",
    "    \"\"\"\n",
    "\n",
    "    fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = np.asarray(y_true)\n",
    "\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "\n",
    "    nfalse = 0\n",
    "\n",
    "    auc = 0\n",
    "\n",
    "    n = len(y_true)\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        y_i = y_true[i]\n",
    "\n",
    "        nfalse += 1 - y_i\n",
    "\n",
    "        auc += y_i * nfalse\n",
    "\n",
    "    auc /= nfalse * (n - nfalse)\n",
    "\n",
    "    return auc\n",
    "\n",
    "\n",
    "def eval_auc_lgb(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast auc eval function for lgb.\n",
    "    \"\"\"\n",
    "    return \"auc\", fast_auc(y_true, y_pred), True\n",
    "\n",
    "\n",
    "class CustomAUC(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def get_auc(y_true, y_prob):\n",
    "        \"\"\"\n",
    "        fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n",
    "        \"\"\"\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_true = y_true[np.argsort(y_prob)]\n",
    "        nfalse = 0\n",
    "        auc = 0\n",
    "        n = len(y_true)\n",
    "        for i in range(n):\n",
    "            y_i = y_true[i]\n",
    "            nfalse += 1 - y_i\n",
    "            auc += y_i * nfalse\n",
    "        auc /= nfalse * (n - nfalse)\n",
    "        return auc\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return True  # greater is better\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        y_true = np.array(target).astype(int)\n",
    "        approx = approxes[:, 1]\n",
    "\n",
    "        score = self.get_auc(y_true, approx)\n",
    "        return score, 1\n",
    "\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "\n",
    "\n",
    "def get_time():\n",
    "    return time.ctime().replace(\" \", \"_\").replace(\"__\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "\n",
    "def preprocess(data, is_test=False):\n",
    "    cors_high = [\n",
    "        \"feature_424\",\n",
    "        \"feature_285\",\n",
    "        \"feature_141\",\n",
    "        \"feature_285\",\n",
    "        \"feature_48\",\n",
    "        \"feature_178\",\n",
    "        \"feature_285\",\n",
    "        \"feature_381\",\n",
    "        \"feature_239\",\n",
    "        \"feature_158\",\n",
    "        \"feature_103\",\n",
    "        \"feature_208\",\n",
    "        \"feature_9\",\n",
    "        \"feature_428\",\n",
    "        \"feature_323\",\n",
    "        \"feature_410\",\n",
    "        \"feature_98\",\n",
    "        \"feature_285\",\n",
    "        \"feature_9\",\n",
    "        \"feature_379\",\n",
    "        \"feature_495\",\n",
    "        \"feature_323\",\n",
    "        \"feature_98\",\n",
    "    ]\n",
    "    data = data.drop(columns=cors_high)\n",
    "\n",
    "    data[\"feature_47_div_feature_133\"] = data.feature_47 / data.feature_133\n",
    "    data[\"feature_47_div_feature_253\"] = data[\"feature_47\"] / data[\"feature_253\"]\n",
    "    data[\"feature_459_div_feature_166\"] = data[\"feature_459\"] / data[\"feature_166\"]\n",
    "    data[\"feature_173_div_feature_467\"] = data[\"feature_173\"] / data[\"feature_467\"]\n",
    "    data[\"feature_467_div_feature_343\"] = data[\"feature_467\"] / data[\"feature_343\"]\n",
    "    data[\"feature_201_div_feature_47\"] = data[\"feature_201\"] / data[\"feature_47\"]\n",
    "    data[\"feature_87_div_feature_492\"] = data[\"feature_87\"] / data[\"feature_492\"]\n",
    "    data[\"feature_201_div_feature_467\"] = data[\"feature_201\"] / data[\"feature_467\"]\n",
    "    data[\"feature_83_div_feature_47\"] = data[\"feature_83\"] / data[\"feature_47\"]\n",
    "    data[\"feature_423_div_feature_87\"] = data[\"feature_423\"] / data[\"feature_87\"]\n",
    "\n",
    "    need_take = [\n",
    "        \"feature_5\",\n",
    "        \"feature_11\",\n",
    "        \"feature_12\",\n",
    "        \"feature_14\",\n",
    "        \"feature_18\",\n",
    "        \"feature_29\",\n",
    "        \"feature_31\",\n",
    "        \"feature_35\",\n",
    "        \"feature_37\",\n",
    "        \"feature_42\",\n",
    "        \"feature_45\",\n",
    "        \"feature_47\",\n",
    "        \"feature_50\",\n",
    "        \"feature_53\",\n",
    "        \"feature_66\",\n",
    "        \"feature_68\",\n",
    "        \"feature_80\",\n",
    "        \"feature_81\",\n",
    "        \"feature_86\",\n",
    "        \"feature_87\",\n",
    "        \"feature_97\",\n",
    "        \"feature_100\",\n",
    "        \"feature_106\",\n",
    "        \"feature_114\",\n",
    "        \"feature_119\",\n",
    "        \"feature_131\",\n",
    "        \"feature_133\",\n",
    "        \"feature_138\",\n",
    "        \"feature_139\",\n",
    "        \"feature_147\",\n",
    "        \"feature_151\",\n",
    "        \"feature_153\",\n",
    "        \"feature_154\",\n",
    "        \"feature_157\",\n",
    "        \"feature_161\",\n",
    "        \"feature_164\",\n",
    "        \"feature_167\",\n",
    "        \"feature_168\",\n",
    "        \"feature_172\",\n",
    "        \"feature_174\",\n",
    "        \"feature_186\",\n",
    "        \"feature_194\",\n",
    "        \"feature_195\",\n",
    "        \"feature_197\",\n",
    "        \"feature_205\",\n",
    "        \"feature_230\",\n",
    "        \"feature_234\",\n",
    "        \"feature_244\",\n",
    "        \"feature_246\",\n",
    "        \"feature_247\",\n",
    "        \"feature_251\",\n",
    "        \"feature_253\",\n",
    "        \"feature_259\",\n",
    "        \"feature_262\",\n",
    "        \"feature_264\",\n",
    "        \"feature_265\",\n",
    "        \"feature_270\",\n",
    "        \"feature_272\",\n",
    "        \"feature_318\",\n",
    "        \"feature_325\",\n",
    "        \"feature_331\",\n",
    "        \"feature_332\",\n",
    "        \"feature_336\",\n",
    "        \"feature_353\",\n",
    "        \"feature_364\",\n",
    "        \"feature_365\",\n",
    "        \"feature_371\",\n",
    "        \"feature_383\",\n",
    "        \"feature_386\",\n",
    "        \"feature_388\",\n",
    "        \"feature_390\",\n",
    "        \"feature_412\",\n",
    "        \"feature_421\",\n",
    "        \"feature_439\",\n",
    "        \"feature_449\",\n",
    "        \"feature_451\",\n",
    "        \"feature_452\",\n",
    "        \"feature_454\",\n",
    "        \"feature_462\",\n",
    "        \"feature_467\",\n",
    "        \"feature_470\",\n",
    "        \"feature_490\",\n",
    "        \"feature_498\",\n",
    "        \"feature_47_div_feature_133\",\n",
    "        \"feature_47_div_feature_253\",\n",
    "        \"feature_173_div_feature_467\",\n",
    "        \"feature_201_div_feature_47\",\n",
    "    ]\n",
    "\n",
    "    if \"target\" in data.columns:\n",
    "        need_take.append(\"target\")\n",
    "    if is_test:\n",
    "        need_take.append(\"id\")\n",
    "\n",
    "    data = data[need_take]\n",
    "    return data\n",
    "\n",
    "\n",
    "def train_model(X_train, X_val, X_test, y_train, y_val, model_type, model_params):\n",
    "    model = None\n",
    "    if model_type == \"cat\":\n",
    "        model = CatBoostClassifier(eval_metric=\"AUC\", **model_params)\n",
    "        model.fit(train_set, eval_set=eval_set, use_best_model=True, verbose=200)\n",
    "\n",
    "        train_set = Pool(data=X_train, label=y_train)\n",
    "        eval_set = Pool(data=X_val, label=y_val)\n",
    "\n",
    "        oof_prediction = model.predict_proba(X_val)\n",
    "        test_prediction = model.predict_proba(X_test)\n",
    "\n",
    "    elif model_type == \"lgbm\":\n",
    "        model = LGBMClassifier(**model_params, n_jobs=-1)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=eval_auc_lgb)\n",
    "\n",
    "        oof_prediction = model.predict_proba(X_val)\n",
    "        test_prediction = model.predict_proba(X_test, num_iteration=model.best_iteration_)\n",
    "\n",
    "    elif model_type == \"xgb\":\n",
    "        train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X_train.columns)\n",
    "        valid_data = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_train.columns)\n",
    "\n",
    "        watchlist = [(train_data, \"train\"), (valid_data, \"valid_data\")]\n",
    "        model = xgb.train(dtrain=train_data, num_boost_round=1000, evals=watchlist, params=model_params)\n",
    "\n",
    "        oof_prediction = model.predict_proba(\n",
    "            xgb.DMatrix(X_val, feature_names=X_train.columns), ntree_limit=model.best_ntree_limit\n",
    "        )\n",
    "        test_prediction = model.predict_proba(\n",
    "            xgb.DMatrix(X_test, feature_names=X_train.columns), ntree_limit=model.best_ntree_limit\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(\"Wrong model_type is provided.\\n\")\n",
    "\n",
    "    return oof_prediction, test_prediction, model\n",
    "\n",
    "\n",
    "def save_model(model, model_type, file_idx, model_idx):\n",
    "    try:\n",
    "        if model_type == \"cat\":\n",
    "            save_path = f\"CATBOOST_{file_idx}_{model_idx}_{get_time}\"\n",
    "            model.save_model(save_path, format=\"cbm\")\n",
    "        elif model_type == \"lgbm\":\n",
    "            save_path = f\"LGMB_{file_idx}_{model_idx}_{get_time()}\"\n",
    "            model.save_model(save_path, num_iteration=model.best_iteration)\n",
    "        elif model_type == \"xgb\":\n",
    "            save_path = f\"XGBOOST_{file_idx}_{model_idx}_{get_time()}\"\n",
    "            model.save_model(save_path)\n",
    "    except:\n",
    "        print(f\"no save completed for model {model_type}_{model_idx}\\tfile{file_idx}\")\n",
    "    finally:\n",
    "        print(f\"{get_time()} SAVE_MODEL COMPLETED\")\n",
    "\n",
    "\n",
    "def get_metadata_from_files(X_val, X_test, y_val, models_list, types_of_models=3, train_files=None):\n",
    "\n",
    "    if any(not os.path.isfile(train_file) for train_file in train_files):\n",
    "        raise RuntimeError(\"Provide correct train_files. \" + \"Current is {}\".format(train_files))\n",
    "\n",
    "    train_metadata = np.zeros((len(X_val), len(models_list) * types_of_models))\n",
    "    test_metadata = np.zeros((len(X_test), len(models_list) * types_of_models))\n",
    "\n",
    "    train_files = sorted(train_files)\n",
    "    for file_idx, filename in enumerate(train_files):\n",
    "        print(\"File: {}\".format(filename))\n",
    "        print(\"Started at: {}\".format(time.ctime()))\n",
    "\n",
    "        s = time.time()\n",
    "        X_train = pd.read_csv(filename)\n",
    "        e = time.time()\n",
    "        print(\"{} to read a file\".format(e - s))\n",
    "\n",
    "        X_train = X_train.drop(columns=[\"smpl\", \"id\"])\n",
    "        X_train = preprocess(X_train)\n",
    "        y_train = X_test[\"target\"]\n",
    "\n",
    "        try:\n",
    "            X_train.pop(\"target\")\n",
    "        except:\n",
    "            print(\"Target isn't dropped\")\n",
    "\n",
    "        for model_idx, (model_type, model_params) in enumerate(models_list):\n",
    "            model = None\n",
    "            # IT MUST BE PROBAS\n",
    "            train_prediction, test_prediction, model = train_model(\n",
    "                X_train, X_val, X_test, y_train, y_val, model_type, model_params\n",
    "            )\n",
    "\n",
    "            model_type_column = model_idx // types_of_models\n",
    "\n",
    "            train_metadata[:, model_type_column] += train_prediction[:, 1]\n",
    "            test_metadata[:, model_type_column] += test_prediction[:, 1]\n",
    "\n",
    "            try:\n",
    "                save_model(model, model_type, file_idx, model_idx)\n",
    "            except Exception as e:\n",
    "                print(\"Something went wrong with saving\")\n",
    "                print(e.what())\n",
    "            finally:\n",
    "                print(\"\\tModel: {}_{}\".format(models_list[model_idx][0], model_idx))\n",
    "\n",
    "        del X_train\n",
    "\n",
    "    train_metadata /= len(models_list // types_of_models)\n",
    "    test_metadata /= len(models_list // types_of_models)\n",
    "\n",
    "    return train_metadata, test_metadata\n",
    "\n",
    "\n",
    "def predict_test(X_test, ids, model, test_path=test_path, name=None):\n",
    "    if name is None:\n",
    "        name = f\"UNTITLED\"\n",
    "\n",
    "    dt = pd.DataFrame({\"id\": ids, \"target\": model.predict_proba(X_test)[:, 1]})\n",
    "\n",
    "    dt.to_csv(f\"submission_{name}_{get_time}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a02ee5",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beebdcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "SEEDS = [42, 1337, 407, 666, 1111]\n",
    "\n",
    "catboost_params_0 = {\n",
    "    \"iterations\": 2000,\n",
    "    \"verbose\": False,\n",
    "    \"max_depth\": 10,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"custom_metric\": CustomAUC(),\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    \"task_type\": \"GPU\" if torch.cuda.is_available() else \"CPU\",\n",
    "    \"random_state\": SEEDS[0],\n",
    "    \"metric_period\": 50,\n",
    "    \"bootstrap_type\":\"Poisson\" if torch.cuda.is_available() else \"Bernoulli\",\n",
    "    \"subsample\": 0.8\n",
    "}\n",
    "catboost_params_1 = {\n",
    "    \"iterations\": 1000,\n",
    "    \"verbose\": False,\n",
    "    \"max_depth\": 10,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"custom_metric\": CustomAUC(),\n",
    "    \"random_seed\": SEED,\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    \"task_type\": \"GPU\" if torch.cuda.is_available() else \"CPU\",\n",
    "    \"random_state\": SEEDS[1],\n",
    "    \"metric_period\": 50,\n",
    "    \"bootstrap_type\":\"Poisson\" if torch.cuda.is_available() else \"Bernoulli\",\n",
    "    \"subsample\": 0.8\n",
    "}\n",
    "catboost_params_2 = {\n",
    "    \"iterations\": 2000,\n",
    "    \"verbose\": False,\n",
    "    \"max_depth\": 15,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"custom_metric\": CustomAUC(),\n",
    "    \"random_seed\": SEED,\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    \"task_type\": \"GPU\" if torch.cuda.is_available() else \"CPU\",\n",
    "    \"random_state\": SEEDS[2],\n",
    "    \"metric_period\": 50,\n",
    "    \"bootstrap_type\":\"Poisson\" if torch.cuda.is_available() else \"Bernoulli\",\n",
    "    \"subsample\": 0.66\n",
    "}\n",
    "catboost_params_3 = {\n",
    "    \"iterations\": 1000,\n",
    "    \"verbose\": False,\n",
    "    \"max_depth\": 5,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"custom_metric\": CustomAUC(),\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    \"task_type\": \"GPU\" if torch.cuda.is_available() else \"CPU\",\n",
    "    \"random_state\": SEEDS[3],\n",
    "    \"metric_period\": 50,\n",
    "    # \"bootstrap_type\":\"Poisson\" if torch.cuda.is_available() else \"Bernoulli\",\n",
    "    # \"subsample\": 0.8\n",
    "}\n",
    "catboost_params_4 = {\n",
    "    \"iterations\": 1000,\n",
    "    \"verbose\": False,\n",
    "    \"max_depth\": 20,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"custom_metric\": CustomAUC(),\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    \"task_type\": \"GPU\" if torch.cuda.is_available() else \"CPU\",\n",
    "    \"random_state\": SEEDS[4],\n",
    "    \"bagging_temperature\": 1.0,\n",
    "    \"metric_period\": 50\n",
    "    # \"bootstrap_type\":\"Poisson\" if torch.cuda.is_available() else \"Bernoulli\",\n",
    "    # \"subsample\": 0.8\n",
    "}\n",
    "\n",
    "lgbm_params_0 = {\n",
    "    \"seed\": SEEDS[0], \n",
    "    \"device_type\": \"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "    \"objective\": \"binary\", \n",
    "    \"num_iterations\": 500,\n",
    "    \"metric\": \"auc\",\n",
    "    \"min_data_in_leaf\": 50,\n",
    "    \"bagging_fraction\": 0.8, \n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_freq\": 50\n",
    "}\n",
    "\n",
    "lgbm_params_1 = {\n",
    "    \"seed\": SEEDS[1], \n",
    "    \"device_type\": \"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "    \"objective\": \"binary\", \n",
    "    \"num_iterations\": 500,\n",
    "    \"metric\": \"auc\",\n",
    "    \"min_data_in_leaf\": 10,\n",
    "    \"bagging_fraction\": 0.8, \n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_freq\": 50\n",
    "}\n",
    "\n",
    "lgbm_params_2 = {\n",
    "    \"seed\": SEEDS[2], \n",
    "    \"device_type\": \"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "    \"objective\": \"binary\", \n",
    "    \"num_iterations\": 1000,\n",
    "    \"metric\": \"auc\",\n",
    "    \"min_data_in_leaf\": 100,\n",
    "    \"bagging_fraction\": 0.8, \n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_freq\": 30\n",
    "}\n",
    "lgbm_params_3 = {\n",
    "    \"seed\": SEEDS[3], \n",
    "    \"device_type\": \"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "    \"objective\": \"binary\", \n",
    "    \"num_iterations\": 500,\n",
    "    \"metric\": \"auc\",\n",
    "    \"min_data_in_leaf\": 50,\n",
    "    \"bagging_fraction\": 0.8, \n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_freq\": 50\n",
    "}\n",
    "\n",
    "lgbm_params_4 = {\n",
    "    \"seed\": SEEDS[4], \n",
    "    \"device_type\": \"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "    \"objective\": \"binary\", \n",
    "    \"num_iterations\": 1000,\n",
    "    \"metric\": \"auc\",\n",
    "    \"min_data_in_leaf\": 50,\n",
    "    \"bagging_fraction\": 0.8, \n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_freq\": 20\n",
    "}\n",
    "\n",
    "xgb_params_0 = {\n",
    "    \"early_stopping_rounds\":100, \n",
    "    \"verbose_eval\": 200, \n",
    "    \"device\": \"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.8, \n",
    "    \"sampling_method\": \"gradient_based\",\n",
    "    \"lambda\": 5,\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"seed\": SEEDS[0]\n",
    "}\n",
    "\n",
    "xgb_params_1 = {\n",
    "    \"early_stopping_rounds\":100, \n",
    "    \"verbose_eval\": 200, \n",
    "    \"device\": \"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.8, \n",
    "    \"sampling_method\": \"gradient_based\",\n",
    "    \"lambda\": 5,\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"seed\": SEEDS[1]\n",
    "}\n",
    "\n",
    "xgb_params_2 = {\n",
    "    \"early_stopping_rounds\":100, \n",
    "    \"verbose_eval\": 200, \n",
    "    \"device\": \"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.8, \n",
    "    \"sampling_method\": \"gradient_based\",\n",
    "    \"lambda\": 5,\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"seed\": SEEDS[2]\n",
    "}\n",
    "\n",
    "xgb_params_3 = {\n",
    "    \"early_stopping_rounds\":100, \n",
    "    \"verbose_eval\": 200, \n",
    "    \"device\": \"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.8, \n",
    "    \"sampling_method\": \"gradient_based\",\n",
    "    \"lambda\": 5,\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"seed\": SEEDS[3]\n",
    "}\n",
    "\n",
    "xgb_params_4 = {\n",
    "    \"early_stopping_rounds\":100, \n",
    "    \"verbose_eval\": 200, \n",
    "    \"device\": \"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.8,\n",
    "    \"lambda\": 5,\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"seed\": SEEDS[4]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0f77d",
   "metadata": {},
   "source": [
    "## Are params correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    m = CatBoostClassifier(**catboost_params_0)\n",
    "    m = CatBoostClassifier(**catboost_params_1)\n",
    "    m = CatBoostClassifier(**catboost_params_2)\n",
    "    m = CatBoostClassifier(**catboost_params_3)\n",
    "    m = CatBoostClassifier(**catboost_params_4)\n",
    "\n",
    "    m = LGBMClassifier(**lgbm_params_0)\n",
    "    m = LGBMClassifier(**lgbm_params_1)\n",
    "    m = LGBMClassifier(**lgbm_params_2)\n",
    "    m = LGBMClassifier(**lgbm_params_3)\n",
    "    m = LGBMClassifier(**lgbm_params_4)\n",
    "\n",
    "    m = xgb.XGBClassifier(**xgb_params_0)\n",
    "    m = xgb.XGBClassifier(**xgb_params_1)\n",
    "    m = xgb.XGBClassifier(**xgb_params_2)\n",
    "    m = xgb.XGBClassifier(**xgb_params_3)\n",
    "    m = xgb.XGBClassifier(**xgb_params_4)\n",
    "except:\n",
    "    assert 1 == 0, \"wtf... wrong params\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27fc2d5",
   "metadata": {},
   "source": [
    "## Models to train: CatBoost, LGBM, XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b288cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T17:42:54.874312Z",
     "iopub.status.busy": "2024-11-04T17:42:54.873740Z",
     "iopub.status.idle": "2024-11-04T17:42:54.880200Z",
     "shell.execute_reply": "2024-11-04T17:42:54.879193Z"
    },
    "papermill": {
     "duration": 0.028323,
     "end_time": "2024-11-04T17:42:54.882795",
     "exception": false,
     "start_time": "2024-11-04T17:42:54.854472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_list = [\n",
    "    [\n",
    "        [\"cat\", catboost_params_0],\n",
    "        [\"cat\", catboost_params_1],\n",
    "        [\"cat\", catboost_params_2],\n",
    "        [\"cat\", catboost_params_3],\n",
    "        [\"cat\", catboost_params_4],\n",
    "        \n",
    "        [\"lgbm\", lgbm_params_0],\n",
    "        [\"lgbm\", lgbm_params_1],\n",
    "        [\"lgbm\", lgbm_params_2],\n",
    "        [\"lgbm\", lgbm_params_3],\n",
    "        [\"lgbm\", lgbm_params_4],\n",
    "\n",
    "        [\"xgb\", xgb_params_0],\n",
    "        [\"xgb\", xgb_params_1],\n",
    "        [\"xgb\", xgb_params_2],\n",
    "        [\"xgb\", xgb_params_3],\n",
    "        [\"xgb\", xgb_params_4]\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2656ea0",
   "metadata": {},
   "source": [
    "## Validation:: train_10\n",
    "\n",
    "## Test: concatenated test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_filename = \"/kaggle/input/train-one/trainset/train_10.csv\"\n",
    "\n",
    "s = time.time()\n",
    "X_val = pd.read_csv(val_filename)\n",
    "y_val = X_val['target']\n",
    "\n",
    "X_val = preprocess(X_val)\n",
    "X_val = X_val.drop(columns=['smpl', 'id'])\n",
    "e = time.time()\n",
    "\n",
    "print(\"{} to preprocess a file {}\".format(e - s, val_filename))\n",
    "\n",
    "\n",
    "def read_test(test_path=test_path):\n",
    "    X_test = None\n",
    "    for test_file in os.listdir(test_path):\n",
    "        if X_test is None:\n",
    "            X_test = pd.read_csv(test_file)\n",
    "        else:\n",
    "            X_test = pd.concat((X_test, pd.read_csv(test_file)))\n",
    "    \n",
    "    return preprocess(X_test, is_test=True).drop(columns=['smpl'])\n",
    "\n",
    "s = time.time()\n",
    "X_test = read_test(test_path)\n",
    "test_id = X_test.pop('id')\n",
    "\n",
    "e = time.time()\n",
    "print(\"{} to preprocess test files\".format(e - s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4c3e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T17:42:54.923181Z",
     "iopub.status.busy": "2024-11-04T17:42:54.922640Z",
     "iopub.status.idle": "2024-11-04T17:47:27.518944Z",
     "shell.execute_reply": "2024-11-04T17:47:27.518003Z"
    },
    "papermill": {
     "duration": 272.63604,
     "end_time": "2024-11-04T17:47:27.537387",
     "exception": false,
     "start_time": "2024-11-04T17:42:54.901347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_files = [\n",
    "    \"/kaggle/input/train-one/train_1.csv\",\n",
    "    \"/kaggle/input/train-one/trainset/train_2.csv\",\n",
    "    \"/kaggle/input/train-one/trainset/train_3.csv\",\n",
    "    \"/kaggle/input/train-one/trainset/train_4.csv\",\n",
    "    \"/kaggle/input/train-one/trainset/train_5.csv\",\n",
    "    \"/kaggle/input/train-one/trainset/train_6.csv\", \n",
    "    \"/kaggle/input/train-one/trainset/train_7.csv\", \n",
    "    \"/kaggle/input/train-one/trainset/train_8.csv\", \n",
    "    \"/kaggle/input/train-one/trainset/train_9.csv\"\n",
    "]\n",
    "\n",
    "train_metadata, test_metadata = get_metadata_from_files(\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    models_list=models_list,\n",
    "    train_files=train_files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f88c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T17:47:27.572144Z",
     "iopub.status.busy": "2024-11-04T17:47:27.571774Z",
     "iopub.status.idle": "2024-11-04T17:47:27.578101Z",
     "shell.execute_reply": "2024-11-04T17:47:27.577164Z"
    },
    "papermill": {
     "duration": 0.026468,
     "end_time": "2024-11-04T17:47:27.580060",
     "exception": false,
     "start_time": "2024-11-04T17:47:27.553592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_metadata.shape, test_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8443386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T17:47:27.613772Z",
     "iopub.status.busy": "2024-11-04T17:47:27.613097Z",
     "iopub.status.idle": "2024-11-04T17:47:28.167287Z",
     "shell.execute_reply": "2024-11-04T17:47:28.166130Z"
    },
    "papermill": {
     "duration": 0.573231,
     "end_time": "2024-11-04T17:47:28.169397",
     "exception": false,
     "start_time": "2024-11-04T17:47:27.596166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(X_val.shape, X_test.shape)\n",
    "print(train_metadata.shape, test_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cac9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = X_test.pop('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a01789",
   "metadata": {},
   "source": [
    "# Predictions on metadata\n",
    "\n",
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab314c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T17:47:28.203908Z",
     "iopub.status.busy": "2024-11-04T17:47:28.203554Z",
     "iopub.status.idle": "2024-11-04T17:50:34.847890Z",
     "shell.execute_reply": "2024-11-04T17:50:34.846813Z"
    },
    "papermill": {
     "duration": 186.663619,
     "end_time": "2024-11-04T17:50:34.849975",
     "exception": false,
     "start_time": "2024-11-04T17:47:28.186356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "catboost_cv = {\n",
    "    \"verbose\": 100,\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"eval_metric\": CustomAUC(),\n",
    "    \"use_best_model\": True,\n",
    "    \"task_type\": \"GPU\" if torch.cuda.is_available() else \"CPU\",\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    'l2_leaf_reg': [5, 10, 50]\n",
    "}\n",
    "\n",
    "catboost_meta = CatBoostClassifier()\n",
    "catboost_meta_params, cv_results = catboost_meta.randomized_search(train_metadata, y_val, cv=5, verbose=100, plot=True)['params']\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca328e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params for catboost metamodel\\n\")\n",
    "print(catboost_meta_params)\n",
    "\n",
    "predict_test(X_test, test_id, catboost_meta, name=\"catboost_metamodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c76dc5",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dc1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_params = {\n",
    "    \"max_iter\": 3000, \n",
    "    \"penalty\": [\"l2\", \"l1\", \"elasticnet\", None],\n",
    "    \"tol\": [1e-4], \n",
    "    \"warm_start\": True,\n",
    "    \"solver\":[\"saga\", \"liblinear\"]\n",
    "}\n",
    "\n",
    "logreg_meta = GridSearchCV(estimator=LogisticRegression, *logreg_params, verbose=1, scoring=\"roc-auc\")\n",
    "\n",
    "logreg_meta.fit(train_metadata, y_val)\n",
    "\n",
    "logreg_metamodel = logreg_meta.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params for LogReg metamodel\\n\")\n",
    "print(logreg_metamodel.get_params)\n",
    "\n",
    "print(\"Logreg metamodel best score: {}\".format(logreg_meta.best_score_))\n",
    "\n",
    "predict_test(X_test, test_id, logreg_metamodel, name=\"logreg_metamodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c4a341",
   "metadata": {},
   "source": [
    "# Initial data + model predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb3a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_val.shape, X_test.shape)\n",
    "X_OOF_train = np.hstack((X_val, train_metadata))\n",
    "X_OOF_test = np.hstack((X_test, test_metadata))\n",
    "print(X_OOF_train.shape, X_OOF_test.shape, X_OOF_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c9cef",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "catboost_cv = {\n",
    "    \"verbose\": 100,\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"eval_metric\": CustomAUC(),\n",
    "    \"task_type\": \"GPU\" if torch.cuda.is_available() else \"CPU\",\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    'l2_leaf_reg': [1, 10],\n",
    "    \"use_best_model\": True\n",
    "}\n",
    "\n",
    "catboost_oof = CatBoostClassifier()\n",
    "catboost_oof_best, cv_results = catboost_oof.randomized_search(X_OOF_train, y_val, cv=5, verbose=100, plot=True)\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe224380",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1478315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T17:50:57.679122Z",
     "iopub.status.busy": "2024-11-04T17:50:57.678758Z",
     "iopub.status.idle": "2024-11-04T17:50:57.684761Z",
     "shell.execute_reply": "2024-11-04T17:50:57.683831Z"
    },
    "papermill": {
     "duration": 0.055888,
     "end_time": "2024-11-04T17:50:57.686638",
     "exception": false,
     "start_time": "2024-11-04T17:50:57.630750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Путь к папке с тренировочными данными\n",
    "\n",
    "# # path_train = '../train'\n",
    "\n",
    "\n",
    "\n",
    "# # Путь к папке с тестовыми данными\n",
    "\n",
    "# path_test = '../test'\n",
    "\n",
    "\n",
    "\n",
    "# # Объединим тестовые данные в единый датасет test\n",
    "\n",
    "\n",
    "\n",
    "# # Получим список путей к файлам в папке test\n",
    "\n",
    "# filenames_test = glob.glob(path_test + \"/*.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# # Создадим список для записи считанных файлов test\n",
    "\n",
    "# data_files_test = []\n",
    "\n",
    "\n",
    "\n",
    "# def compression(filename, features=['target', 'smpl', 'id']):\n",
    "#   # Переводим переменные в глобальную область видимости\n",
    "#   global data, base_info, transformed_data, result\n",
    "#   # Считываем файл данных\n",
    "#   data = pd.read_csv(filename)\n",
    "#   # Отделяем базовые данные\n",
    "#   base_info = data[features]\n",
    "#   # Возвращаем результат обработки\n",
    "#   return result\n",
    "\n",
    "\n",
    "\n",
    "# # Считаем и обработаем все файлы test, после чего добавим их в список\n",
    "\n",
    "# for filename in filenames_test:\n",
    "\n",
    "#   data_files_test.append(compression(filename, features=['smpl', 'id']))\n",
    "\n",
    "\n",
    "\n",
    "# # Объединим тестовые данные в единый датасет\n",
    "\n",
    "# test_data = pd.concat(data_files_test, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# # Выведем первые 10 строк тренировочных данных\n",
    "\n",
    "# display(test_data.head(10))\n",
    "\n",
    "\n",
    "\n",
    "# # Удостоверимся, что перед нами данные только из выборки test\n",
    "\n",
    "# display(test_data['smpl'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce8784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T17:50:58.065793Z",
     "iopub.status.busy": "2024-11-04T17:50:58.065073Z",
     "iopub.status.idle": "2024-11-04T17:50:58.069728Z",
     "shell.execute_reply": "2024-11-04T17:50:58.068856Z"
    },
    "papermill": {
     "duration": 0.054203,
     "end_time": "2024-11-04T17:50:58.071600",
     "exception": false,
     "start_time": "2024-11-04T17:50:58.017397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_test_pred = gbdt_clf.predict_proba(test_data.drop('smpl', axis=1))\n",
    "\n",
    "\n",
    "\n",
    "# # Переведем предсказание в формат Series\n",
    "\n",
    "# y_test_pred = pd.Series(y_test_pred[:, 1])\n",
    "\n",
    "\n",
    "\n",
    "# # Добавим данные предсказания к датасету\n",
    "\n",
    "# test_data['target'] = y_test_pred\n",
    "\n",
    "\n",
    "\n",
    "# # Сохраняем итоговые данные об id и предсказаниях в формате csv\n",
    "\n",
    "# test_data[['id', 'target']].to_csv('baseline_submission_case2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6001437,
     "sourceId": 9797570,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 581.381607,
   "end_time": "2024-11-04T17:51:00.393794",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-04T17:41:19.012187",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
